{"cells":[{"cell_type":"markdown","metadata":{"id":"IRZAusNkkjD6"},"source":["**라이브러리 임포트**"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"K83thxLqqJ61","executionInfo":{"status":"ok","timestamp":1733113596277,"user_tz":-540,"elapsed":8480,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["import os\n","import json\n","import random\n","import shutil\n","import cv2\n","import math\n","\n","from google.colab import drive\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","from torchvision.datasets import ImageFolder\n","from torchvision import transforms, models, datasets\n","from torch.utils.data import DataLoader, Subset"]},{"cell_type":"markdown","metadata":{"id":"419v39A8GQ-A"},"source":["**데이터셋 unzip**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18852,"status":"ok","timestamp":1732861909633,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"T_46dgIdpSf4","outputId":"69570486-2586-4f40-be8b-c9373bb0bfd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201295,"status":"ok","timestamp":1731672852929,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"XjLJ0hM1qB0H","outputId":"437f43f0-9064-4c77-f8a6-e28803254424"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/CAB/CAB_dataset/JPEGImages\n"]}],"source":["%cd /content/drive/MyDrive/CAB/CAB_dataset/JPEGImages\n","!unzip -qq \"/content/drive/MyDrive/CAB/CAB_dataset/JPEGImages/images_bbox.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152358,"status":"ok","timestamp":1731673005280,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"NgqLPUCVqDXJ","outputId":"9e607d12-e49c-4d8a-a2ec-8ef30e0b8dec"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/CAB/CAB_dataset/Annotations\n"]}],"source":["%cd /content/drive/MyDrive/CAB/CAB_dataset/Annotations\n","!unzip -qq \"/content/drive/MyDrive/CAB/CAB_dataset/Annotations/label_bbox.zip\""]},{"cell_type":"markdown","source":["**시드 고정**"],"metadata":{"id":"ZWMVFXT3ahXm"}},{"cell_type":"code","source":["torch.manual_seed(42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LCZu01EajNf","executionInfo":{"status":"ok","timestamp":1732861909634,"user_tz":-540,"elapsed":7,"user":{"displayName":"정서영","userId":"11814773768061491291"}},"outputId":"36d4e6cd-29ba-46ac-e4fd-5dffcf84b1a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7e37b84d1d30>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"THY1Br4gq-8P"},"source":["**데이터 라벨링**"]},{"cell_type":"markdown","metadata":{"id":"aiBVR9Oou_Uu"},"source":["파일 경로 변환\n","- /content/drive/MyDrive/CAB/CAB_dataset/JPEGImages 하위 디렉토리에 있는 이미지를 /content/drive/MyDrive/CAB/CAB_dataset/JPEGImages로 옮긴다.\n","- /content/drive/MyDrive/CAB/CAB_dataset/Annotations 하위 디렉토리에 있는 이미지를 /content/drive/MyDrive/CAB/CAB_dataset/Annotations로 옮긴다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivkR7gKSuugA"},"outputs":[],"source":["def move_file(base_dir):\n","  for root, dirs, files in os.walk(base_dir):\n","    for file in files:\n","        if file.lower().endswith(('.jpg', 'json')):\n","            source_path = os.path.join(root, file)\n","            destination_path = os.path.join(base_dir, file)\n","\n","            shutil.move(source_path, destination_path)\n","\n","jpeg_dir = \"/content/drive/MyDrive/CAB/CAB_dataset/JPEGImages\"\n","annot_dir = \"/content/drive/MyDrive/CAB/CAB_dataset/Annotations\"\n","\n","move_file(jpeg_dir)\n","move_file(annot_dir)"]},{"cell_type":"markdown","metadata":{"id":"zEP_Pgl0kvel"},"source":["입과 눈 사진을 저장할 폴더를 만들어 준다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDL7ofFGvBIM"},"outputs":[],"source":["data_root = \"/content/drive/MyDrive/CAB/CAB_dataset/\"\n","eyes_mouth = os.path.join(data_root, \"EyesMouth\")\n","os.makedirs(eyes_mouth, exist_ok=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_RDzMQPygXI"},"outputs":[],"source":["class_mapping = {\n","      \"Face\": 0,\n","      \"Leye\": 1,\n","      \"Reye\": 2,\n","      \"Mouth\": 3,\n","      \"Cigar\": 4,\n","      \"Phone\": 5\n","}"]},{"cell_type":"markdown","metadata":{"id":"I7hP6Lfr6amh"},"source":["이미지에서 양쪽 눈과 입 사진을 잘라서 저장한다.\n","이때 파일명은 기존 파일명_클래스 이름_Open 혹은 기존 파일명_클래스 이름_Close로 한다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vh6V_BqCvjHv"},"outputs":[],"source":["for image in os.listdir(jpeg_dir):\n","  if image.endswith('jpg'):\n","    name = os.path.splitext(image)[0]\n","\n","    img_path = os.path.join(jpeg_dir, image)\n","    annot_path = os.path.join(annot_dir, name + '.json')\n","\n","    with open(annot_path, 'r', encoding='utf-8') as f:\n","      data = json.load(f)\n","\n","    for obj, bbox in data[\"ObjectInfo\"][\"BoundingBox\"].items():\n","      if bbox[\"isVisible\"] and class_mapping[obj] in [1, 2, 3]:\n","\n","        x1, y1, x2, y2 = bbox[\"Position\"]\n","\n","        Is_open = \"Open\" if bbox[\"Opened\"] else \"Close\"\n","\n","        img = cv2.imread(img_path)\n","        crop_img = img[y1:y2, x1:x2]\n","\n","        img_dst = os.path.join(eyes_mouth, f\"{name}_{obj}_{Is_open}.jpg\")\n","        cv2.imwrite(img_dst, crop_img)"]},{"cell_type":"markdown","metadata":{"id":"bvDgDHKJ3zKG"},"source":["파일명을 참고하여 이미지를 open 혹은 close 폴더로 옮긴다.\n","\n","\n","\n","```python\n","# /content/drive/MyDrive/CAB/CAB_dataset/fs/\n","# ├── open/\n","# │   └── 파일명_클래스 이름_Open.jpg\n","# ├── close/\n","#      └── 파일명_클래스 이름_Close.jpg\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":1097,"status":"error","timestamp":1732595156408,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"LUZfhCEi3_bO","outputId":"fa9d30a4-cbde-47e1-8a49-81afe1081722"},"outputs":[{"ename":"FileExistsError","evalue":"[Errno 17] File exists: '/content/drive/MyDrive/CAB/CAB_dataset/fs/open'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b0c5427f505e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclose_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"close\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/CAB/CAB_dataset/fs/open'"]}],"source":["data_root = \"/content/drive/MyDrive/CAB/CAB_dataset/\"\n","\n","fs_root = os.path.join(data_root, \"fs\")\n","open_root = os.path.join(fs_root, \"open\")\n","close_root = os.path.join(fs_root, \"close\")\n","\n","os.makedirs(open_root, exist_ok=False)\n","os.makedirs(close_root, exist_ok=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZyD0U5H4VmH"},"outputs":[],"source":["for file in os.listdir(eyes_mouth):\n","  if file.endswith('.jpg') and 'Open' in file:\n","    img_src = os.path.join(eyes_mouth, file)\n","    img_dst = os.path.join(open_root, file)\n","\n","  elif file.endswith('.jpg') and 'Close' in file:\n","    img_src = os.path.join(eyes_mouth, file)\n","    img_dst = os.path.join(close_root, file)\n","\n","  shutil.copy2(img_src, img_dst)\n"]},{"cell_type":"markdown","metadata":{"id":"ZKkNWBujF9fr"},"source":["**데이터 undersampling**"]},{"cell_type":"markdown","metadata":{"id":"F4WkYpwj8OIQ"},"source":["다음으로, 모든 Image의 절대 경로가 적힌 리스트를 만든다."]},{"cell_type":"code","source":["data_root = \"/content/drive/MyDrive/CAB/CAB_dataset/\"\n","\n","fs_root = os.path.join(data_root, \"fs\")"],"metadata":{"id":"diWxowLwmezv","executionInfo":{"status":"ok","timestamp":1733113602283,"user_tz":-540,"elapsed":935,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56982,"status":"ok","timestamp":1733113659259,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"bqOahdk_F7A5","outputId":"5519f1f1-1aa7-4271-b305-3a0a5b299ce4"},"outputs":[{"output_type":"stream","name":"stdout","text":["클래스별 인덱스: {'close': 0, 'open': 1}\n","클래스별 샘플 수: [8661, 15364]\n","데이터셋 크기: 24025\n"]}],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomRotation(degrees=(30)),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","dataset = ImageFolder(root=fs_root, transform=transform)\n","\n","class_to_idx = dataset.class_to_idx\n","print(f'클래스별 인덱스: {class_to_idx}')\n","\n","class_counts = [0] * len(class_to_idx)\n","for _, target in dataset.samples:\n","    class_counts[target] += 1\n","\n","print(f\"클래스별 샘플 수: {class_counts}\")\n","print(f\"데이터셋 크기: {len(dataset)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"_Vc-7akjC64s"},"source":["추가 코드\n","\n","close eye와 close mouth의 샘플 수 비율은 비슷하지만 open eye 샘플 수가 open mouth 샘플 수의 약 6배이다."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1733113659260,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"6Y4Gdv3a_zW9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8bddcff1-30c6-4f5f-c245-7e46c8b151ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["close samples: 8661\n","open samples: 15364\n"]}],"source":["close_samples = []\n","open_samples = []\n","\n","for sample, target in dataset.samples:\n","  if target == 0:\n","    close_samples.append((sample, target))\n","  else:\n","    open_samples.append((sample, target))\n","\n","print(f\"close samples: {len(close_samples)}\")\n","print(f\"open samples: {len(open_samples)}\")"]},{"cell_type":"markdown","metadata":{"id":"8F-b8_vqAK2H"},"source":["데이터 불균형 문제와 제공된 GPU RAM, 학습 속도 등을 고려하여 클래스별 샘플 수를 줄여준다.\n","\n","한 가지 추가적으로 고려해야 할 점은, 각 class 안의 eye sample과 mouth sample의 비율이다."]},{"cell_type":"code","source":["e_close = []\n","e_open = []\n","m_close = []\n","m_open = []"],"metadata":{"id":"ugS2Vim_qQic","executionInfo":{"status":"ok","timestamp":1733113659260,"user_tz":-540,"elapsed":18,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["for sample, target in dataset.samples :\n","  if target == 0:\n","    if 'eye' in sample:\n","      e_close.append((sample, target))\n","    if 'Mouth' in sample:\n","      m_close.append((sample, target))\n","  else:\n","    if 'eye' in sample:\n","      e_open.append((sample, target))\n","    if 'Mouth' in sample:\n","      m_open.append((sample, target))"],"metadata":{"id":"zysQLeGvpOLH","executionInfo":{"status":"ok","timestamp":1733113659260,"user_tz":-540,"elapsed":18,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["보다시피, open class 안에 eye sample이 mouth sample보다 약 6배는 더 많은 것을 알 수 있다."],"metadata":{"id":"ms2pUz7drvFM"}},{"cell_type":"code","source":["print(f\"close eye samples: {len(e_close)}\")\n","print(f\"close mouth samples: {len(m_close)}\")\n","print(f\"open eye samples: {len(e_open)}\")\n","print(f\"open mouth samples: {len(m_open)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wL0RGI8-qgBw","executionInfo":{"status":"ok","timestamp":1733113659260,"user_tz":-540,"elapsed":18,"user":{"displayName":"정서영","userId":"11814773768061491291"}},"outputId":"3ea12a1b-19a6-4f22-b82e-f17fbe472e30"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["close eye samples: 4593\n","close mouth samples: 4068\n","open eye samples: 12898\n","open mouth samples: 2466\n"]}]},{"cell_type":"markdown","source":["따라서 각 class의 비율뿐만 아니라 class 안의 mouth, eye sample이 비율도 고려하여 dataset을 나눈다.\n","\n","여기서는 각 class별 샘플 수를 2500개로 하고, 각 클래스에 속한 eye samples과 mouth samples의 비율을 1 : 1로 하였다."],"metadata":{"id":"rTf1bsf5r_iX"}},{"cell_type":"code","source":["random.shuffle(e_close)\n","random.shuffle(e_open)"],"metadata":{"id":"LEB1HkCDsMs2","executionInfo":{"status":"ok","timestamp":1733113659260,"user_tz":-540,"elapsed":15,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["close_samples = e_close[:2000] + m_close[:2000]\n","open_samples = e_open[:2000] + m_open[:2000]"],"metadata":{"id":"DUTFAnrZsRps","executionInfo":{"status":"ok","timestamp":1733113659260,"user_tz":-540,"elapsed":15,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["dataset.samples = close_samples + open_samples"],"metadata":{"id":"VUVbKoPcqcYW","executionInfo":{"status":"ok","timestamp":1733113659261,"user_tz":-540,"elapsed":15,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N-r0VJK1rG6d"},"source":["**train/val/test loader 생성**"]},{"cell_type":"markdown","metadata":{"id":"sd-HtlAr84WI"},"source":["전체 이미지를 6:2:2 비율로 나누어 train set, validation set, test set을 생성한다.\n","\n","ImageFolder는 instance를 직접 섞는 걸 허용하지 않는다. 따라서 무작위로 섞인 인덱스를 이용하여 훈련/검증/테스트 데이터셋을 만든다.\n"]},{"cell_type":"code","source":["dataset_indices = list(range(len(dataset)))\n","\n","random.shuffle(dataset_indices)\n","\n","train_size = int(0.6 * len(dataset))\n","val_size = int(0.2 * len(dataset))\n","test_size = val_size\n","\n","train_dataset = Subset(dataset, dataset_indices[:train_size])\n","val_dataset = Subset(dataset, dataset_indices[train_size:train_size+val_size])\n","test_dataset = Subset(dataset, dataset_indices[train_size+val_size:])"],"metadata":{"id":"yrBh8t65pCzF","executionInfo":{"status":"ok","timestamp":1733113659261,"user_tz":-540,"elapsed":15,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1733113659261,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"QUoDyBso87dh","outputId":"17be514a-1fc6-4057-bbf8-22222373ca32"},"outputs":[{"output_type":"stream","name":"stdout","text":["length of train dataset:  4800\n","length of val dataset:  1600\n","length of test dataset:  1600\n"]}],"source":["print(\"length of train dataset: \", len(train_dataset))\n","print(\"length of val dataset: \", len(val_dataset))\n","print(\"length of test dataset: \", len(test_dataset))"]},{"cell_type":"markdown","metadata":{"id":"bfDBuE8X9K8N"},"source":["다음으로, 훈련/검증/테스트 데이터로더를 생성한다.\n","\n","- num_workers: 2개의 프로세서가 병렬로 데이터를 불러와 이력 데이터가 더 빨리 준비될 수 있도록 한다.\n","- pin_memory=True: CPU에서 GPU로 데이터를 전송할 때 발생하는 복사 작업을 빠르게 할 수 있도록 도와준다."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1733113659261,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"UFQ3W3NwFg7k"},"outputs":[],"source":["# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, pin_memory=True)"]},{"cell_type":"markdown","metadata":{"id":"Glrb9tv0FTuh"},"source":["**분류 모델 생성**"]},{"cell_type":"markdown","metadata":{"id":"UpOtc48YpnQ3"},"source":["분류 모델로는 이전 프로젝트에서 우수한 성능을 보였던 ResNet50 모델을 선택하였다. 최적화 기법으로는 Adam optimizer를 사용하였으며, 학습률(lr)은 0.0001로 설정하였다. 또한, 배치 사이즈(batch size)는 32로 초기화하였다.\n","\n","(지난 프로젝트 결과, ResNet50 모델에서 <Adam optimizer/lr = 0.0001/batch size = 64> 조합일 때 가장 최상의 결과를 얻었다. 이번 프로젝트에서도 최상의 결과를 얻고자 비슷한 조합을 사용했으며, 제공된 GPU RAM을 고려하여 batch size만 32로 수정하였다.)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1733113659261,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"-lBReLhf-SQH"},"outputs":[],"source":["# resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ScoNb4kk-iiZ","executionInfo":{"status":"ok","timestamp":1733113659261,"user_tz":-540,"elapsed":10,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["# class MyResNet50(nn.Module):\n","#     def __init__(self, pretrained_model):\n","#         super(MyResNet50, self).__init__()\n","#         self.backbone = pretrained_model\n","\n","#         self.dropout = nn.Dropout(0.3)\n","#         self.extra_layer = nn.Linear(1000, 2) # open/close 판단\n","#         self.softmax = nn.Softmax(dim=1)\n","\n","#     def forward(self, x):\n","#         x = self.backbone(x)\n","#         x = self.dropout(x)\n","#         x = self.softmax(self.extra_layer(x))\n","#         return x"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"i6cW-ceX-wFd","executionInfo":{"status":"ok","timestamp":1733113659262,"user_tz":-540,"elapsed":10,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["# myresnet50 = MyResNet50(resnet50)\n","\n","# optimizer = optim.Adam(myresnet50.parameters(), lr=0.0001)\n","# criterion = nn.CrossEntropyLoss()\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"VFGPWFeWk5Ac"},"source":["추가 코드"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ZcNktnVVlFO7","executionInfo":{"status":"ok","timestamp":1733113659262,"user_tz":-540,"elapsed":10,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["# base_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)"]},{"cell_type":"markdown","metadata":{"id":"3YbIEjYxndBO"},"source":["\"modules\"는 자신에게 속하는 모든 submodule들을 표시\n","\n","\"children\"은 한 단계 아래의 submodule까지만 표시\n","\n","https://data-scientist-han.tistory.com/110"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1733113659262,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"8qhg9oghkqTD"},"outputs":[],"source":["# for name, module in base_model.named_modules():\n","#   print (name, module)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"bYtxbUidmhwF","executionInfo":{"status":"ok","timestamp":1733113659262,"user_tz":-540,"elapsed":9,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["class CompoundScaledResNet50(nn.Module):\n","  def __init__(self, width_mult=1.1, depth_mult=1.2, resolution_mult=1.15):\n","    super(CompoundScaledResNet50, self).__init__()\n","    self.base_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n","\n","    self.width_mult = width_mult\n","    self.depth_mult = depth_mult\n","    self.resolution_mult = resolution_mult\n","\n","    self.input_resolution = int(224 * resolution_mult) # increase the resolution of images\n","\n","    #self._modify_initial_layers()\n","    self._apply_width_scaling_to_bottlenecks()\n","    # self._modify_downsample_layers()\n","    self._apply_depth_scaling()\n","\n","  def _apply_width_scaling_to_bottlenecks(self):\n","    for name, module in self.base_model.named_modules():\n","      if isinstance(module, models.resnet.Bottleneck):\n","\n","        orig_conv2 = module.conv2 # middle layer of bottleneck\n","\n","        scaled_channels = int(orig_conv2.out_channels * self.width_mult) # increase the channel of images\n","\n","        new_conv1 = nn.Conv2d(\n","            in_channels = module.conv1.in_channels, # keep original input\n","            out_channels = scaled_channels,\n","            kernel_size = 1,\n","            stride = module.conv1.stride,\n","            bias = False\n","        )\n","\n","        new_conv2 = nn.Conv2d(\n","            in_channels = scaled_channels,\n","            out_channels = scaled_channels,\n","            kernel_size = 3,\n","            stride = module.conv2.stride,\n","            padding = 1,\n","            bias = False\n","        )\n","\n","        new_conv3 = nn.Conv2d(\n","            in_channels = scaled_channels,\n","            out_channels = module.conv3.out_channels,\n","            kernel_size = 1,\n","            bias = False\n","        )\n","\n","        new_weight1 = torch.randn(scaled_channels, module.conv1.in_channels, 1, 1)\n","        new_weight2 = torch.randn(scaled_channels, scaled_channels, 3, 3)\n","        new_weight3 = torch.randn(module.conv3.out_channels, scaled_channels, 1, 1)\n","\n","        init.kaiming_uniform_(new_weight1, a=math.sqrt(5))\n","        init.kaiming_uniform_(new_weight2, a=math.sqrt(5))\n","        init.kaiming_uniform_(new_weight3, a=math.sqrt(5))\n","\n","        new_conv1.weight.data = new_weight1\n","        new_conv2.weight.data = new_weight2\n","        new_conv3.weight.data = new_weight3\n","\n","        new_bn1 = nn.BatchNorm2d(scaled_channels)\n","        new_bn2 = nn.BatchNorm2d(scaled_channels)\n","        new_bn3 = nn.BatchNorm2d(module.conv3.out_channels)\n","\n","        module.conv1 = new_conv1\n","        module.bn1 = new_bn1\n","\n","        module.conv2 = new_conv2\n","        module.bn2 = new_bn2\n","\n","        module.conv3 = new_conv3\n","        module.bn3 = new_bn3\n","\n","  def _modify_downsample_layers(self):\n","    for name, module in self.base_model.named_modules():\n","      if isinstance(module, models.resnet.Bottleneck) and module.downsample is not None:\n","        conv1_in_channels = module.conv1.in_channels\n","\n","        if hasattr(module, 'downsample'):\n","          module.downsample = nn.Sequential(\n","              nn.Conv2d(\n","                  in_channels = conv1_in_channels,\n","                  out_channels = module.downsample[0].out_channels,\n","                  kernel_size = 1,\n","                  stride = module.downsample[0].stride,\n","                  bias = False\n","              ),\n","              nn.BatchNorm2d(module.downsample[0].out_channels)\n","          )\n","\n","  def _apply_depth_scaling(self):\n","    for name, child in self.base_model.named_children():\n","      if isinstance(child, nn.Sequential):\n","        new_depth = math.ceil(len(child) * self.depth_mult) # increase the depth\n","\n","        if new_depth > len(child):\n","          additional_layers = [child[-1] for _ in range(new_depth - len(child))] # copy the last layer\n","          setattr(self.base_model, name, nn.Sequential(*list(child), *additional_layers)) # original seq + added layers\n","\n","  def forward(self, x):\n","    x = nn.functional.interpolate(x, size=(self.input_resolution, self.input_resolution), mode='bilinear')\n","    return self.base_model(x)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"o_9ntHZek6lQ","executionInfo":{"status":"ok","timestamp":1733113659262,"user_tz":-540,"elapsed":9,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["class MyCompoundScaledResNet50(nn.Module):\n","  def __init__(self, width_mult=1.1, depth_mult=1.2, resolution_mult=1.0):\n","    super(MyCompoundScaledResNet50, self).__init__()\n","\n","    self.backbone = CompoundScaledResNet50(\n","        width_mult=width_mult,\n","        depth_mult=depth_mult,\n","        resolution_mult=resolution_mult\n","    )\n","\n","    # self.swish = nn.SiLU()\n","    self.dropout = nn.Dropout(0.3)\n","    self.extra_layer = nn.Linear(1000, 1)\n","\n","  def forward(self, x):\n","    x = self.backbone(x)\n","    # x = self.swish(x)\n","    x = self.dropout(x)\n","    x = self.extra_layer(x)\n","    return x"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"hEl9uq5ljbFW","executionInfo":{"status":"ok","timestamp":1733113663292,"user_tz":-540,"elapsed":4038,"user":{"displayName":"정서영","userId":"11814773768061491291"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2c062f8-5e16-4298-b3f9-f498649440cc"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 107MB/s]\n"]}],"source":["new_resnet = MyCompoundScaledResNet50().cuda()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1733113663292,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"dWxsORlivErt","outputId":"49de27a1-9814-42e4-8e34-762efce1c0e4"},"outputs":[{"output_type":"stream","name":"stdout","text":[" MyCompoundScaledResNet50(\n","  (backbone): CompoundScaledResNet50(\n","    (base_model): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 70, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(70, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 70, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(70, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 70, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(70, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(256, 70, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(70, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(140, 140, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(140, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(140, 140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(140, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(140, 140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(140, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(140, 140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(140, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(512, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(140, 140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(140, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (6): Bottleneck(\n","          (conv1): Conv2d(1024, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (7): Bottleneck(\n","          (conv1): Conv2d(1024, 281, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(281, 281, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(281, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 563, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(563, 563, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(563, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 563, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(563, 563, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(563, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 563, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(563, 563, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(563, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(2048, 563, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(563, 563, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(563, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (extra_layer): Linear(in_features=1000, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n"]}],"source":["for name, module in new_resnet.named_modules():\n","    print(name, module)\n","    break"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"pG2wjXOFkJVA","executionInfo":{"status":"ok","timestamp":1733113663292,"user_tz":-540,"elapsed":9,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["optimizer = optim.NAdam(new_resnet.parameters(), lr=0.0001)\n","\n","criterion = nn.CrossEntropyLoss()\n","# criterion = nn.BCEWithLogitsLoss()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0)"],"metadata":{"id":"uZq0V8VU1Zs1","executionInfo":{"status":"ok","timestamp":1733113663292,"user_tz":-540,"elapsed":8,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3AsVQaiUFNpi"},"source":["**훈련/검증/테스트 함수 정의**"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"QksJsWa3HADz","executionInfo":{"status":"ok","timestamp":1733113663292,"user_tz":-540,"elapsed":7,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["def train(model):\n","  model.train()\n","\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","    data, target = data.to(device), target.to(device)\n","\n","    optimizer.zero_grad()\n","\n","    output = model(data)\n","\n","    loss = criterion(output, target)\n","    loss.backward()\n","\n","    optimizer.step()\n","  scheduler.step()\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"EDf95mlmqHaF","executionInfo":{"status":"ok","timestamp":1733113663292,"user_tz":-540,"elapsed":7,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[],"source":["def val(model, epoch):\n","  model.eval()\n","\n","  val_loss = 0\n","  correct = 0\n","\n","  with torch.no_grad():\n","    for data, target in val_loader:\n","      data, target = data.to(device), target.to(device)\n","\n","      output = model(data)\n","\n","      val_loss += criterion(output, target).item()\n","      pred = output.argmax(dim=1, keepdim=True)\n","      correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","  val_loss /= len(val_loader.dataset)\n","  accuracy = 100. * correct / len(val_loader.dataset)\n","\n","  print(f\"Epoch: {epoch}, Average loss: {val_loss:.4f}, Accuracy: {correct}/{len(val_loader.dataset)} ({accuracy:.2f}%)\")\n","\n","  return val_loss"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1733113663293,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"n3Ixf3LoqK98"},"outputs":[],"source":["def test(model):\n","  model.eval()\n","\n","  test_loss = 0\n","  correct = 0\n","\n","  with torch.no_grad():\n","    for data, target in test_loader:\n","      data, target = data.to(device), target.to(device)\n","\n","      output = model(data)\n","\n","      test_loss += criterion(output, target).item()\n","      pred = output.argmax(dim=1, keepdim=True)\n","      correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","  test_loss /= len(test_loader.dataset)\n","  accuracy = 100. * correct / len(test_loader.dataset)\n","\n","  print(f\"Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\")\n"]},{"cell_type":"markdown","metadata":{"id":"JTFcBL6jrOdy"},"source":["**EarlyStopping 정의**"]},{"cell_type":"markdown","metadata":{"id":"X4bLt8dmFSDW"},"source":["overfitting을 방지하기 위해 earlystopping을 사용한다."]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1733113663293,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"tWzOvaWMHGqB"},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, patience=10, verbose=False, counter=0, best_loss=float('inf')):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = counter\n","        self.best_loss = best_loss\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss, model):\n","        if val_loss < self.best_loss:\n","            self.counter = 0\n","            self.best_loss = val_loss\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/CAB/CAB_dataset/model/best_resnet_model.pth')\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","              self.early_stop = True"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1733113663293,"user":{"displayName":"정서영","userId":"11814773768061491291"},"user_tz":-540},"id":"ugVjepZCGLPD"},"outputs":[],"source":["num_epochs = 100"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXsW0jarHI_Z","outputId":"82cda825-d88d-4465-915f-c248bd5c852d","executionInfo":{"status":"ok","timestamp":1733124151057,"user_tz":-540,"elapsed":10487771,"user":{"displayName":"정서영","userId":"11814773768061491291"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Average loss: 0.0182, Accuracy: 1159/1600 (72.44%)\n","Epoch: 2, Average loss: 0.0191, Accuracy: 1122/1600 (70.12%)\n","Epoch: 3, Average loss: 0.0187, Accuracy: 1137/1600 (71.06%)\n","Epoch: 4, Average loss: 0.0199, Accuracy: 1081/1600 (67.56%)\n","Epoch: 5, Average loss: 0.0212, Accuracy: 1008/1600 (63.00%)\n","Epoch: 6, Average loss: 0.0202, Accuracy: 1066/1600 (66.62%)\n","Epoch: 7, Average loss: 0.0186, Accuracy: 1145/1600 (71.56%)\n","Epoch: 8, Average loss: 0.0193, Accuracy: 1111/1600 (69.44%)\n","Epoch: 9, Average loss: 0.0190, Accuracy: 1124/1600 (70.25%)\n","Epoch: 10, Average loss: 0.0177, Accuracy: 1191/1600 (74.44%)\n","Epoch: 11, Average loss: 0.0168, Accuracy: 1232/1600 (77.00%)\n","Epoch: 12, Average loss: 0.0179, Accuracy: 1180/1600 (73.75%)\n","Epoch: 13, Average loss: 0.0171, Accuracy: 1220/1600 (76.25%)\n","Epoch: 14, Average loss: 0.0186, Accuracy: 1145/1600 (71.56%)\n","Epoch: 15, Average loss: 0.0176, Accuracy: 1195/1600 (74.69%)\n","Epoch: 16, Average loss: 0.0169, Accuracy: 1231/1600 (76.94%)\n","Epoch: 17, Average loss: 0.0173, Accuracy: 1204/1600 (75.25%)\n","Epoch: 18, Average loss: 0.0163, Accuracy: 1262/1600 (78.88%)\n","Epoch: 19, Average loss: 0.0153, Accuracy: 1316/1600 (82.25%)\n","Epoch: 20, Average loss: 0.0154, Accuracy: 1311/1600 (81.94%)\n","Epoch: 21, Average loss: 0.0154, Accuracy: 1308/1600 (81.75%)\n","Epoch: 22, Average loss: 0.0153, Accuracy: 1314/1600 (82.12%)\n","Epoch: 23, Average loss: 0.0149, Accuracy: 1330/1600 (83.12%)\n","Epoch: 24, Average loss: 0.0151, Accuracy: 1322/1600 (82.62%)\n","Epoch: 25, Average loss: 0.0152, Accuracy: 1313/1600 (82.06%)\n","Epoch: 26, Average loss: 0.0149, Accuracy: 1338/1600 (83.62%)\n","Epoch: 27, Average loss: 0.0148, Accuracy: 1339/1600 (83.69%)\n","Epoch: 28, Average loss: 0.0146, Accuracy: 1353/1600 (84.56%)\n","Epoch: 29, Average loss: 0.0150, Accuracy: 1326/1600 (82.88%)\n","Epoch: 30, Average loss: 0.0147, Accuracy: 1340/1600 (83.75%)\n","Epoch: 31, Average loss: 0.0147, Accuracy: 1346/1600 (84.12%)\n","Epoch: 32, Average loss: 0.0151, Accuracy: 1323/1600 (82.69%)\n","Epoch: 33, Average loss: 0.0150, Accuracy: 1330/1600 (83.12%)\n","Epoch: 34, Average loss: 0.0146, Accuracy: 1348/1600 (84.25%)\n","Epoch: 35, Average loss: 0.0145, Accuracy: 1350/1600 (84.38%)\n","Epoch: 36, Average loss: 0.0147, Accuracy: 1345/1600 (84.06%)\n","Epoch: 37, Average loss: 0.0147, Accuracy: 1343/1600 (83.94%)\n","Epoch: 38, Average loss: 0.0151, Accuracy: 1319/1600 (82.44%)\n","Epoch: 39, Average loss: 0.0149, Accuracy: 1331/1600 (83.19%)\n","Epoch: 40, Average loss: 0.0158, Accuracy: 1284/1600 (80.25%)\n","Epoch: 41, Average loss: 0.0151, Accuracy: 1321/1600 (82.56%)\n","Epoch: 42, Average loss: 0.0154, Accuracy: 1305/1600 (81.56%)\n","Epoch: 43, Average loss: 0.0149, Accuracy: 1330/1600 (83.12%)\n","Epoch: 44, Average loss: 0.0163, Accuracy: 1255/1600 (78.44%)\n","Epoch: 45, Average loss: 0.0155, Accuracy: 1304/1600 (81.50%)\n","************************************************************\n","Early stop!\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-34-fb4e2805d808>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  new_resnet.load_state_dict(torch.load('/content/drive/MyDrive/CAB/CAB_dataset/model/best_resnet_model.pth', map_location=device))\n"]},{"output_type":"stream","name":"stdout","text":["Average loss: 0.0146, Accuracy: 1349/1600 (84.31%)\n"]}],"source":["new_resnet.to(device)\n","\n","early_stopping = EarlyStopping(verbose=True)\n","\n","for epoch in range(1, num_epochs + 1):\n","  train(new_resnet)\n","  val_loss = val(new_resnet, epoch)\n","\n","  early_stopping(val_loss, new_resnet)\n","\n","  if early_stopping.early_stop:\n","    print(\"************************************************************\\nEarly stop!\")\n","    new_resnet.load_state_dict(torch.load('/content/drive/MyDrive/CAB/CAB_dataset/model/best_resnet_model.pth', map_location=device))\n","    test(new_resnet)\n","    break"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1iL-9l9r9g4agB-EhY0rToueGVRfwq-hu","authorship_tag":"ABX9TyPqvGez8SX6Fg6Rt4TZt1N9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}